{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "38bc1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from os.path import exists\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "e007e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPortfolio:\n",
    "    \"\"\"\n",
    "    Python ETL script for Friktion user portfolio data. \n",
    "    \n",
    "    Currently supported Instruction Names: \n",
    "        - Deposit\n",
    "        - CancelPendingDeposit\n",
    "        - Withdrawal\n",
    "        - CancelPendingWithdrawal\n",
    "        - ClaimPendingWithdrawal\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 date_start, \n",
    "                 date_end, \n",
    "                 ix_fname='friktion_ix.csv', \n",
    "                 deposit_fname='friktion_deposit.csv', \n",
    "                 deposit_cxl_fname='friktion_deposit_cxl.csv', \n",
    "                 withdraw_fname='friktion_withdraw.csv', \n",
    "                 withdraw_cxl_fname='friktion_withdraw_cancel.csv',\n",
    "                 withdraw_claim_fname='friktion_claim_withdrawal.csv',\n",
    "                 batch_size_days=14, \n",
    "                 batch_size_xfers=50\n",
    "            ):\n",
    "        \"\"\"\n",
    "        :ix_fname:              output csv for instructions\n",
    "        :deposit_fname:         output csv for deposits\n",
    "        :deposit_cxl_fname:     output csv for deposit cancels\n",
    "        :withdraw_fname:        output csv for withdrawals\n",
    "        :withdraw_cxl_fname:    output csv for withdrawal cancels\n",
    "        :withdraw_claim_fname:    output csv for claiming pending withdrawal\n",
    "        :batch_size_days:       batch size in days for query to keep query < 10k rows. Use bigger steps for larger data.\n",
    "        :batch_size_transfers:  batch size transactions for query to keep query < 8kb \n",
    "\n",
    "        \"\"\"\n",
    "        self.volt_program = \"VoLT1mJz1sbnxwq5Fv2SXjdVDgPXrb9tJyC8WpMDkSp\"\n",
    "        self.date_start = date_start\n",
    "        self.date_end = date_end\n",
    "        self.ix_fname = ix_fname\n",
    "        self.deposit_fname = deposit_fname\n",
    "        self.deposit_cxl_fname = deposit_cxl_fname\n",
    "        self.withdraw_fname = withdraw_fname\n",
    "        self.withdraw_cxl_fname = withdraw_cxl_fname\n",
    "        self.withdraw_claim_fname = withdraw_claim_fname\n",
    "        self.batch_size_days = batch_size_days\n",
    "        self.batch_size_xfers = batch_size_xfers\n",
    "        self.df_ix = []\n",
    "\n",
    "\n",
    "    ########################################################################################################\n",
    "    ####################################          Queries             ######################################\n",
    "    ########################################################################################################\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def ix_query(self):\n",
    "        return \"\"\"\n",
    "            query MyQuery {\n",
    "              solana {\n",
    "                instructions(\n",
    "                  time: {between: [\"%s\", \"%s\"]}\n",
    "                  success: {is: true}\n",
    "                  programId: {is: \"VoLT1mJz1sbnxwq5Fv2SXjdVDgPXrb9tJyC8WpMDkSp\"}\n",
    "                ) {\n",
    "                  block {\n",
    "                    timestamp {\n",
    "                      iso8601\n",
    "                    }\n",
    "                  }\n",
    "                  log {\n",
    "                    consumed\n",
    "                    instruction\n",
    "                    logs\n",
    "                  }\n",
    "                  transaction {\n",
    "                    signature\n",
    "                    success\n",
    "                    feePayer\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def xfer_query(self):\n",
    "        return \"\"\"\n",
    "            query MyQuery {\n",
    "              solana(network: solana) {\n",
    "                transfers(\n",
    "                  signature: {in: [%s]}\n",
    "                ) {\n",
    "                  instruction {\n",
    "                    action {\n",
    "                      name\n",
    "                    }\n",
    "                    callPath\n",
    "                  }\n",
    "                  amount(success: {is: true})\n",
    "                  transaction {\n",
    "                    signer\n",
    "                    signature\n",
    "                  }\n",
    "                  block {\n",
    "                    timestamp {\n",
    "                      iso8601\n",
    "                    }\n",
    "                  }\n",
    "                  currency {\n",
    "                    name\n",
    "                    address\n",
    "                    symbol\n",
    "                    decimals\n",
    "                  }\n",
    "                  sender {\n",
    "                    address\n",
    "                    mintAccount\n",
    "                  }\n",
    "                  receiver {\n",
    "                    address\n",
    "                    mintAccount\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    ########################################################################################################\n",
    "    ################################          Helper Functions             #################################\n",
    "    ########################################################################################################\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def run_query(query):  # A simple function to use requests.post to make the API call.\n",
    "        headers = {'X-API-KEY': 'BQYCaXaMZlqZrPCSQVsiJrKtxKRVcSe4'}\n",
    "        request = requests.post('https://graphql.bitquery.io/', json={'query': query}, headers=headers)\n",
    "        if request.status_code == 200:\n",
    "            return request.json()\n",
    "        else:\n",
    "            print(request.reason)\n",
    "            raise Exception('Query failed and return code is {}.{}'.format(request.status_code, query))\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def batch_iterable(iterable, n=1):\n",
    "        \"\"\"\n",
    "        Takes in an iterable and returns an iterable of iterables with len==x\n",
    "        \"\"\"\n",
    "        idxs = []\n",
    "        l = len(iterable)\n",
    "        for idx in range(0, l, n):\n",
    "            idxs.append(iterable[idx:min(idx+n, l)])\n",
    "        return idxs\n",
    "        \n",
    "        \n",
    "    def format_txs_for_query(self, tx_signatures):\n",
    "        \"\"\"\n",
    "        Batches a list of transactions into a list of string formatted transactions for querying. \n",
    "        Each of these strings contain (n=self.batch_size_xfers) unique transaction IDs.\n",
    "        \"\"\"\n",
    "        batched_signatures = self.batch_iterable(tx_signatures, self.batch_size_xfers)\n",
    "        \n",
    "        def format_txs(x):\n",
    "            return str(x)[1:-1].replace(\"\\'\", \"\\\"\").replace(\"\\n\", \"\")\n",
    "        \n",
    "        tx_strs = list(map(format_txs, batched_signatures))\n",
    "\n",
    "        return tx_strs\n",
    "    \n",
    "    \n",
    "    def get_existing_df(self, fname):\n",
    "        # Create output file if doesn't exist\n",
    "        if fname and exists(fname):\n",
    "            return pd.read_csv(fname)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ################################          Data Retrieval             ###################################\n",
    "    ########################################################################################################\n",
    "    \n",
    "    \n",
    "    def get_ix(self, date_start, date_end):\n",
    "        \"\"\"\n",
    "        Runs graphql instruction query for one date range. \n",
    "        \"\"\"\n",
    "        query = self.ix_query % (date_start, date_end)\n",
    "        print(datetime.now(), \"retrieving instructions for {} to {}\".format(date_start, date_end))\n",
    "        result = self.run_query(query)\n",
    "        \n",
    "        # convert GraphQL json to pandas dataframe\n",
    "        df = pd.json_normalize(result['data']['solana']['instructions'])\n",
    "        print(datetime.now(), df.shape[0], \"instructions retrieved\")\n",
    "        \n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"block.timestamp.iso8601\": \"timestamp\", \n",
    "                \"log.consumed\": \"computeUnits\", \n",
    "                \"log.instruction\": \"instructionType\", \n",
    "                \"log.logs\": \"programLogs\", \n",
    "                \"transaction.signature\": \"txSignature\", \n",
    "                \"transaction.success\": \"txSuccess\", \n",
    "                \"transaction.feePayer\": \"txSigner\"\n",
    "            }\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_ix_batch(self):\n",
    "        \"\"\"\n",
    "        Batch the instruction retrieval. Save the shit Drop duplicates. \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        df_ix = self.get_existing_df(self.ix_fname)\n",
    "        \n",
    "        # Batch the days up nice and good so the graphql API calls don't bitch\n",
    "        dates_batched = pd.date_range(self.date_start, self.date_end, freq='7D')\n",
    "        dates_batched = [str(x.isoformat()) for x in dates_batched.append(pd.DatetimeIndex([self.date_end]))]\n",
    "        date_ranges = list(zip(dates_batched, dates_batched[1:]))\n",
    "        \n",
    "        xfers = []\n",
    "        \n",
    "        for date_range in date_ranges:\n",
    "            assert len(date_range)==2\n",
    "            data = self.get_ix(date_range[0], date_range[1])\n",
    "            xfers.append(data)\n",
    "            \n",
    "        df_ix = pd.concat(xfers, ignore_index=False)\n",
    "        df_ix.drop_duplicates().to_csv(self.ix_fname, index=False)\n",
    "        print(datetime.now(), \"final data size: \", df_ix.shape[0])\n",
    "        self.df_ix = df_ix\n",
    "    \n",
    "        \n",
    "    def get_batched_xfers(self, instructionType, fname):\n",
    "        \"\"\"\n",
    "        Get all transfers corresponding to a specific instructionType from Graphql query. \n",
    "        Batch these queries up b/c the string sizes are too large (curse GraphQL for not supporting joins)\n",
    "        \n",
    "        :instructionType: String corresponding to the instruction type of each query. \n",
    "        :fname: Name of where the old df is stored\n",
    "        \n",
    "        \"\"\"\n",
    "        # assert self.df_ix, \"Error: instructions get_ix_batch() must be called before xfers are scraped\"\n",
    "            \n",
    "        temp = self.df_ix.query(\"instructionType=='%s'\" % (instructionType))\n",
    "        \n",
    "        if temp.empty:\n",
    "            print(datetime.now(), \"instructionType was not found in the data... breaking\")\n",
    "            return\n",
    "        \n",
    "        tx_signatures = list(temp[\"txSignature\"].unique())\n",
    "        tx_strs = self.format_txs_for_query(tx_signatures)\n",
    "        \n",
    "        xfers = []\n",
    "        \n",
    "        for tx_str in tx_strs:\n",
    "            query = self.xfer_query % (tx_str)\n",
    "            result = self.run_query(query)\n",
    "            df = pd.json_normalize(result['data']['solana']['transfers'])\n",
    "            xfers.append(df)\n",
    "            # print(datetime.now(), df.shape[0], \"transfers scraped\")\n",
    "\n",
    "        df_xfer = pd.concat(xfers, ignore_index=False)\n",
    "        df_xfer = df_xfer.rename(\n",
    "            columns={\n",
    "                \"block.timestamp.iso8601\": \"timestamp\", \n",
    "                \"instruction.action.name\": \"instructionAction\", \n",
    "                \"instruction.callPath\": \"instructionOrder\", \n",
    "                \"transaction.signer\": \"userAddress\", \n",
    "                \"transaction.signature\": \"txSignature\", \n",
    "                \"currency.symbol\": \"currencySymbol\", \n",
    "                \"currency.name\": \"currencyName\", \n",
    "                \"receiver.address\": \"receiverAddress\", \n",
    "                \"sender.address\": \"senderAddress\", \n",
    "                \"currency.decimals\": \"currencyDecimals\",\n",
    "                \"currency.address\": \"currencyAddress\", \n",
    "            }\n",
    "          )\n",
    "        \n",
    "        print(datetime.now(), df_xfer.shape[0], \"transfers retrieved\")\n",
    "\n",
    "        df_old = self.get_existing_df(fname)\n",
    "        df_final = df_old.append(df_xfer, ignore_index=True).sort_values(\"instructionOrder\")\n",
    "        return df_final\n",
    "    \n",
    "    \n",
    "    #TODO: Get rid of duplicated code here\n",
    "    def parse_deposits(self):\n",
    "        instructionType = 'Deposit'\n",
    "        df_deposit = self.get_batched_xfers(instructionType, self.deposit_fname)\n",
    "\n",
    "        # Get rid of confusing wSOL entries\n",
    "        df_deposit = df_deposit.query('currencyName != \"Wrapped SOL\"')\n",
    "\n",
    "        # The deposit is always the last transfer in the transaction.\n",
    "        df_deposit = df_deposit.query('instructionAction==\"transfer\"').groupby(\"txSignature\").last().reset_index()\n",
    "        \n",
    "        df_deposit.drop_duplicates().to_csv(self.deposit_fname, index=False)\n",
    "        print(datetime.now(), \"Deposit data size: \", df_deposit.shape[0])\n",
    "            \n",
    "            \n",
    "    def parse_withdrawal(self):\n",
    "        instructionType = 'Withdraw'\n",
    "        df_withdraw = self.get_batched_xfers(instructionType, self.withdraw_fname)\n",
    "        \n",
    "        # The deposit is always the last transfer in the transaction.\n",
    "        df_withdraw = df_withdraw.query('instructionAction==\"burn\"').groupby(\"txSignature\").last().reset_index()\n",
    "        \n",
    "        df_withdraw.drop_duplicates().to_csv(self.withdraw_fname, index=False)\n",
    "        print(datetime.now(), \"Withdraw data size: \", df_withdraw.shape[0])        \n",
    "        \n",
    "        \n",
    "    def parse_deposit_cancel(self):\n",
    "        instructionType = 'CancelPendingDeposit'\n",
    "        df_deposit_cxl = self.get_batched_xfers(instructionType, self.deposit_cxl_fname)\n",
    "        \n",
    "        # Get rid of confusing wSOL entries\n",
    "        df_deposit_cxl = df_deposit_cxl.query('currencyName != \"Wrapped SOL\"')\n",
    "\n",
    "        # The deposit is always the last transfer in the transaction.\n",
    "        df_deposit_cxl = df_deposit_cxl.query('instructionAction==\"transfer\"').groupby(\"txSignature\").last().reset_index()\n",
    "        \n",
    "        df_deposit_cxl.drop_duplicates().to_csv(self.deposit_cxl_fname, index=False)\n",
    "        print(datetime.now(), \"Cancel Deposit data size: \", df_deposit_cxl.shape[0])        \n",
    "                \n",
    "        \n",
    "    def parse_withdrawal_cancel(self):\n",
    "        instructionType = 'CancelPendingWithdrawal'\n",
    "        df_withdraw_cxl = self.get_batched_xfers(instructionType, self.withdraw_cxl_fname)\n",
    "        \n",
    "        # Get rid of confusing wSOL entries\n",
    "        df_withdraw_cxl = df_withdraw_cxl.query('currencyName != \"Wrapped SOL\"')\n",
    "\n",
    "        # The deposit is always the last transfer in the transaction.\n",
    "        df_withdraw_cxl = df_withdraw_cxl.query('instructionAction==\"mintTo\"').groupby(\"txSignature\").last().reset_index()\n",
    "        \n",
    "        df_withdraw_cxl.drop_duplicates().to_csv(self.withdraw_cxl_fname, index=False)\n",
    "        print(datetime.now(), \"Cancel Withdraw data size: \", df_withdraw_cxl.shape[0])  \n",
    "        \n",
    "        \n",
    "    def parse_claim_withdrawal(self):\n",
    "        instructionType = 'ClaimPendingWithdrawal'\n",
    "        df_claim_withdraw = self.get_batched_xfers(instructionType, self.withdraw_claim_fname)\n",
    "        \n",
    "        # Get rid of confusing wSOL entries\n",
    "        df_claim_withdraw = df_claim_withdraw.query('currencyName != \"Wrapped SOL\"')\n",
    "\n",
    "        # The deposit is always the last transfer in the transaction.\n",
    "        df_claim_withdraw = df_claim_withdraw.query('instructionAction==\"transfer\"').groupby(\"txSignature\").last().reset_index()\n",
    "        \n",
    "        df_claim_withdraw.drop_duplicates().to_csv(self.withdraw_claim_fname, index=False)\n",
    "        print(datetime.now(), \"Claim Pending Withdraw data size: \", df_claim_withdraw.shape[0])  \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "7c704177",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = \"2021-12-16T00:00:00Z\"\n",
    "date_end = \"2022-03-31T00:00:00Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "19aaa8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MyPortfolio(date_start, date_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "b5adb266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-30 02:26:28.507464 retrieving instructions for 2021-12-16T00:00:00+00:00 to 2021-12-23T00:00:00+00:00\n",
      "2022-03-30 02:26:36.095154 1706 instructions retrieved\n",
      "2022-03-30 02:26:36.096554 retrieving instructions for 2021-12-23T00:00:00+00:00 to 2021-12-30T00:00:00+00:00\n",
      "2022-03-30 02:26:42.011800 2604 instructions retrieved\n",
      "2022-03-30 02:26:42.013725 retrieving instructions for 2021-12-30T00:00:00+00:00 to 2022-01-06T00:00:00+00:00\n",
      "2022-03-30 02:26:51.165003 4377 instructions retrieved\n",
      "2022-03-30 02:26:51.167466 retrieving instructions for 2022-01-06T00:00:00+00:00 to 2022-01-13T00:00:00+00:00\n",
      "2022-03-30 02:27:00.600225 4014 instructions retrieved\n",
      "2022-03-30 02:27:00.603483 retrieving instructions for 2022-01-13T00:00:00+00:00 to 2022-01-20T00:00:00+00:00\n",
      "2022-03-30 02:27:12.367887 6022 instructions retrieved\n",
      "2022-03-30 02:27:12.371374 retrieving instructions for 2022-01-20T00:00:00+00:00 to 2022-01-27T00:00:00+00:00\n",
      "2022-03-30 02:27:21.580970 5413 instructions retrieved\n",
      "2022-03-30 02:27:21.584884 retrieving instructions for 2022-01-27T00:00:00+00:00 to 2022-02-03T00:00:00+00:00\n",
      "2022-03-30 02:27:32.468038 5681 instructions retrieved\n",
      "2022-03-30 02:27:32.469987 retrieving instructions for 2022-02-03T00:00:00+00:00 to 2022-02-10T00:00:00+00:00\n",
      "2022-03-30 02:27:42.261914 4959 instructions retrieved\n",
      "2022-03-30 02:27:42.264474 retrieving instructions for 2022-02-10T00:00:00+00:00 to 2022-02-17T00:00:00+00:00\n",
      "2022-03-30 02:27:51.223528 4144 instructions retrieved\n",
      "2022-03-30 02:27:51.225294 retrieving instructions for 2022-02-17T00:00:00+00:00 to 2022-02-24T00:00:00+00:00\n",
      "2022-03-30 02:28:00.312543 3292 instructions retrieved\n",
      "2022-03-30 02:28:00.315468 retrieving instructions for 2022-02-24T00:00:00+00:00 to 2022-03-03T00:00:00+00:00\n",
      "2022-03-30 02:28:17.540873 3007 instructions retrieved\n",
      "2022-03-30 02:28:17.543592 retrieving instructions for 2022-03-03T00:00:00+00:00 to 2022-03-10T00:00:00+00:00\n",
      "2022-03-30 02:28:27.393798 3286 instructions retrieved\n",
      "2022-03-30 02:28:27.396608 retrieving instructions for 2022-03-10T00:00:00+00:00 to 2022-03-17T00:00:00+00:00\n",
      "2022-03-30 02:28:37.467278 2439 instructions retrieved\n",
      "2022-03-30 02:28:37.468721 retrieving instructions for 2022-03-17T00:00:00+00:00 to 2022-03-24T00:00:00+00:00\n",
      "2022-03-30 02:28:48.123453 3670 instructions retrieved\n",
      "2022-03-30 02:28:48.125000 retrieving instructions for 2022-03-24T00:00:00+00:00 to 2022-03-31T00:00:00+00:00\n",
      "2022-03-30 02:28:57.920573 4935 instructions retrieved\n",
      "2022-03-30 02:28:57.923940 retrieving instructions for 2022-03-31T00:00:00+00:00 to 2022-03-31T00:00:00+00:00\n",
      "2022-03-30 02:28:58.633934 0 instructions retrieved\n",
      "2022-03-30 02:28:59.214032 final data size:  59549\n"
     ]
    }
   ],
   "source": [
    "x.get_ix_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a24152",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.parse_claim_withdrawal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "7ee4c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-30 02:14:04.479336 123 transfers retrieved\n",
      "2022-03-30 02:14:04.499429 Cancel Withdraw data size:  123\n"
     ]
    }
   ],
   "source": [
    "x.parse_withdrawal_cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "e0486664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-30 02:14:13.904903 638 transfers retrieved\n",
      "2022-03-30 02:14:13.925068 Cancel Deposit data size:  227\n"
     ]
    }
   ],
   "source": [
    "x.parse_deposit_cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "6fdfb2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-30 02:18:18.958431 18661 transfers retrieved\n",
      "2022-03-30 02:18:19.071319 Deposit data size:  4767\n"
     ]
    }
   ],
   "source": [
    "x.parse_deposits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "74bce56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-30 02:19:32.392767 7106 transfers retrieved\n",
      "2022-03-30 02:19:32.435373 Withdraw data size:  1817\n"
     ]
    }
   ],
   "source": [
    "x.parse_withdrawal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55d70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
