{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa2897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from os.path import exists\n",
    "import requests\n",
    "import traceback\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95c16ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPortfolio:\n",
    "    \"\"\"\n",
    "    Python ETL script for Friktion user portfolio data. \n",
    "    \n",
    "    Currently supported Instruction Names: \n",
    "        - Deposit\n",
    "        - CancelPendingDeposit\n",
    "        - Withdrawal\n",
    "        - CancelPendingWithdrawal\n",
    "        - ClaimPendingWithdrawal\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 date_start, \n",
    "                 date_end, \n",
    "                 ix_fname='friktion_ix.csv', \n",
    "                 deposit_fname='friktion_deposit.csv', \n",
    "                 deposit_cxl_fname='friktion_deposit_cxl.csv', \n",
    "                 withdraw_fname='friktion_withdraw.csv', \n",
    "                 withdraw_cxl_fname='friktion_withdraw_cancel.csv',\n",
    "                 withdraw_claim_fname='friktion_claim_withdrawal.csv',\n",
    "                 batch_size_days=14, \n",
    "                 batch_size_xfers=75\n",
    "            ):\n",
    "        \"\"\"\n",
    "        :ix_fname:              output csv for instructions\n",
    "        :deposit_fname:         output csv for deposits\n",
    "        :deposit_cxl_fname:     output csv for deposit cancels\n",
    "        :withdraw_fname:        output csv for withdrawals\n",
    "        :withdraw_cxl_fname:    output csv for withdrawal cancels\n",
    "        :withdraw_claim_fname:    output csv for claiming pending withdrawal\n",
    "        :batch_size_days:       batch size in days for query to keep query < 10k rows. Use bigger steps for larger data.\n",
    "        :batch_size_transfers:  batch size transactions for query to keep query < 8kb \n",
    "\n",
    "        \"\"\"\n",
    "        self.volt_program = \"VoLT1mJz1sbnxwq5Fv2SXjdVDgPXrb9tJyC8WpMDkSp\"\n",
    "        self.date_start = date_start\n",
    "        self.date_end = date_end\n",
    "        self.ix_fname = ix_fname\n",
    "        self.deposit_fname = deposit_fname\n",
    "        self.deposit_cxl_fname = deposit_cxl_fname\n",
    "        self.withdraw_fname = withdraw_fname\n",
    "        self.withdraw_cxl_fname = withdraw_cxl_fname\n",
    "        self.withdraw_claim_fname = withdraw_claim_fname\n",
    "        self.batch_size_days = batch_size_days\n",
    "        self.batch_size_xfers = batch_size_xfers\n",
    "        self.df_ix = []\n",
    "        self.friktion_metadata = self.get_friktion_snapshot()\n",
    "\n",
    "\n",
    "    ########################################################################################################\n",
    "    ####################################          Queries             ######################################\n",
    "    ########################################################################################################\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def ix_query(self):\n",
    "        return \"\"\"\n",
    "            query MyQuery {\n",
    "              solana {\n",
    "                instructions(\n",
    "                  time: {between: [\"%s\", \"%s\"]}\n",
    "                  success: {is: true}\n",
    "                  programId: {is: \"VoLT1mJz1sbnxwq5Fv2SXjdVDgPXrb9tJyC8WpMDkSp\"}\n",
    "                ) {\n",
    "                  block {\n",
    "                    timestamp {\n",
    "                      iso8601\n",
    "                    }\n",
    "                  }\n",
    "                  log {\n",
    "                    consumed\n",
    "                    logs\n",
    "                  }\n",
    "                  transaction {\n",
    "                    signature\n",
    "                    success\n",
    "                    feePayer\n",
    "                  }\n",
    "                  data {\n",
    "                    base58\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def xfer_query(self):\n",
    "        return \"\"\"\n",
    "            query MyQuery {\n",
    "              solana(network: solana) {\n",
    "                transfers(\n",
    "                  signature: {in: [%s]}\n",
    "                ) {\n",
    "                  instruction {\n",
    "                    action {\n",
    "                      name\n",
    "                      type\n",
    "                    }\n",
    "                    callPath\n",
    "                  }\n",
    "                  amount(success: {is: true})\n",
    "                  transaction {\n",
    "                    signer\n",
    "                    signature\n",
    "                  }\n",
    "                  block {\n",
    "                    timestamp {\n",
    "                      iso8601\n",
    "                    }\n",
    "                  }\n",
    "                  currency {\n",
    "                    name\n",
    "                    address\n",
    "                    symbol\n",
    "                    decimals\n",
    "                  }\n",
    "                  sender {\n",
    "                    address\n",
    "                    mintAccount\n",
    "                  }\n",
    "                  receiver {\n",
    "                    address\n",
    "                    mintAccount\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    ########################################################################################################\n",
    "    ################################          Helper Functions             #################################\n",
    "    ########################################################################################################\n",
    "    \n",
    "    \n",
    "    # TODO: Add retry logic to this in case of hangups. \n",
    "    @staticmethod\n",
    "    def run_query(query):  # A simple function to use requests.post to make the API call.\n",
    "        headers = {'X-API-KEY': 'BQYCaXaMZlqZrPCSQVsiJrKtxKRVcSe4'}\n",
    "        request = requests.post('https://graphql.bitquery.io/', json={'query': query}, headers=headers)\n",
    "        if request.status_code == 200:\n",
    "            return request.json()\n",
    "        else:\n",
    "            print(request.reason)\n",
    "            raise Exception('Query failed and return code is {}.{}'.format(request.status_code, query))\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def batch_iterable(iterable, n=1):\n",
    "        \"\"\"\n",
    "        Takes in an iterable and returns an iterable of iterables with len==x\n",
    "        \"\"\"\n",
    "        idxs = []\n",
    "        l = len(iterable)\n",
    "        for idx in range(0, l, n):\n",
    "            idxs.append(iterable[idx:min(idx+n, l)])\n",
    "        return idxs\n",
    "        \n",
    "        \n",
    "    def format_txs_for_query(self, tx_signatures):\n",
    "        \"\"\"\n",
    "        Batches a list of transactions into a list of string formatted transactions for querying. \n",
    "        Each of these strings contain (n=self.batch_size_xfers) unique transaction IDs.\n",
    "        \"\"\"\n",
    "        batched_signatures = self.batch_iterable(tx_signatures, self.batch_size_xfers)\n",
    "        \n",
    "        def format_txs(x):\n",
    "            return str(x)[1:-1].replace(\"\\'\", \"\\\"\").replace(\"\\n\", \"\")\n",
    "        \n",
    "        tx_strs = list(map(format_txs, batched_signatures))\n",
    "\n",
    "        return tx_strs\n",
    "    \n",
    "    \n",
    "    def get_existing_df(self, fname):\n",
    "        # Create output file if doesn't exist\n",
    "        if fname and exists(fname):\n",
    "            return pd.read_csv(fname)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    @staticmethod\n",
    "    def instruction_match(instructionData):\n",
    "        if not instructionData or len(instructionData) < 8:\n",
    "            return False\n",
    "        \n",
    "        instructionDescriptor = instructionData[:8]\n",
    "        \n",
    "        if instructionDescriptor == \"PcB3tF1K\":\n",
    "            return \"Withdraw\"\n",
    "        elif instructionDescriptor == \"WuE7Hjns\":\n",
    "            return \"Deposit\"\n",
    "        elif instructionDescriptor == \"V8cW2nMq\":\n",
    "            return \"CancelPendingDeposit\"\n",
    "        elif instructionDescriptor == \"dxUbSCWk\":\n",
    "            return \"CancelPendingWithdrawal\"\n",
    "        elif instructionDescriptor == \"WcTWQsnk\":\n",
    "            return \"ClaimPendingWithdrawal\"\n",
    "        else:\n",
    "            return \"Unclassified\"\n",
    "        \n",
    "        \n",
    "    def get_friktion_snapshot(self):\n",
    "        \"\"\"\n",
    "        Load Friktion Metadata for Volt/Symbol Mapping to join to normal data\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            return pd.DataFrame(\n",
    "                dict(\n",
    "                    json.loads(\n",
    "                        requests.get(\"https://friktion-labs.github.io/mainnet-tvl-snapshots/friktionSnapshot.json\"\n",
    "                        ).content)\n",
    "                  )['allMainnetVolts']\n",
    "            )[[\"globalId\", \"vaultAuthority\", \"shareTokenMint\", \"depositTokenSymbol\", \"depositTokenCoingeckoId\"]]\n",
    "        except Exception as e:\n",
    "            print(datetime.now(), \"Snapshot Data Invalid\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "            \n",
    "    ########################################################################################################\n",
    "    ################################          Data Retrieval             ###################################\n",
    "    ########################################################################################################\n",
    "    \n",
    "    \n",
    "    def get_ix(self, date_start, date_end):\n",
    "        \"\"\"\n",
    "        Runs graphql instruction query for one date range. \n",
    "        \"\"\"\n",
    "        print(date_start, date_end)\n",
    "        query = self.ix_query % (date_start, date_end)\n",
    "        print(datetime.now(), \"retrieving instructions for {} to {}\".format(date_start, date_end))\n",
    "        result = self.run_query(query)\n",
    "        \n",
    "        # convert GraphQL json to pandas dataframe\n",
    "        df = pd.json_normalize(result['data']['solana']['instructions'])\n",
    "        print(datetime.now(), df.shape[0], \"instructions retrieved\")\n",
    "        \n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"block.timestamp.iso8601\": \"timestamp\", \n",
    "                \"log.consumed\": \"computeUnits\", \n",
    "                \"log.logs\": \"programLogs\", \n",
    "                \"transaction.signature\": \"txSignature\", \n",
    "                \"transaction.success\": \"txSuccess\", \n",
    "                \"transaction.feePayer\": \"txSigner\",\n",
    "                \"data.base58\": \"instructionData\"\n",
    "            }\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_ix_batch(self):\n",
    "        \"\"\"\n",
    "        Batch the instruction retrieval. Save the shit Drop duplicates. \n",
    "\n",
    "        \"\"\"\n",
    "                \n",
    "        # Batch the days up nice and good so the graphql API calls don't bitch\n",
    "        dates_batched = pd.date_range(self.date_start, self.date_end, freq='7D')\n",
    "        dates_batched = [str(x.isoformat()) for x in dates_batched.append(pd.DatetimeIndex([self.date_end]))]\n",
    "        date_ranges = list(zip(dates_batched, dates_batched[1:]))\n",
    "        \n",
    "        ixs = []\n",
    "        \n",
    "        for date_range in date_ranges:\n",
    "            assert len(date_range)==2\n",
    "            data = self.get_ix(date_range[0], date_range[1])\n",
    "            ixs.append(data)\n",
    "            \n",
    "        df_ix = pd.concat(ixs, ignore_index=False)\n",
    "        df_ix[\"instructionType\"] = df_ix.instructionData.apply(lambda x: self.instruction_match(x))\n",
    "        \n",
    "        # Store df_ix before we write it to the DataFrame so we avoid getting xfers for every single ix\n",
    "        self.df_ix = df_ix.drop_duplicates()\n",
    "        print(datetime.now(), \"final instruction data size: \", df_ix.shape[0])\n",
    "\n",
    "        df_old = self.get_existing_df(self.ix_fname)\n",
    "        df = pd.concat([df_old, df_ix], ignore_index=True)\n",
    "        df.to_csv(self.ix_fname, index=False)\n",
    "        print(datetime.now(), \"wrote instruction data to csv...\")\n",
    "\n",
    "        \n",
    "        \n",
    "    def get_batched_xfers(self, instructionType, fname):\n",
    "        \"\"\"\n",
    "        Get all transfers corresponding to a specific instructionType from Graphql query. \n",
    "        Batch these queries up b/c the string sizes are too large (curse GraphQL for not supporting joins)\n",
    "        \n",
    "        :instructionType: String corresponding to the instruction type of each query. \n",
    "        :fname: Name of where the old df is stored\n",
    "        \n",
    "        \"\"\"\n",
    "        # assert self.df_ix, \"Error: instructions get_ix_batch() must be called before xfers are scraped\"\n",
    "            \n",
    "        temp = self.df_ix.query(\"instructionType == '%s'\" % (instructionType))\n",
    "        \n",
    "        if temp.empty:\n",
    "            print(datetime.now(), \"instructionType was not found in the data... breaking\")\n",
    "            return\n",
    "        \n",
    "        tx_signatures = list(temp[\"txSignature\"].unique())\n",
    "        tx_strs = self.format_txs_for_query(tx_signatures)\n",
    "        print(datetime.now(), len(tx_strs), \"signature batches required...\")\n",
    "        xfers = []\n",
    "        \n",
    "        for i, tx_str in enumerate(tx_strs):\n",
    "            query = self.xfer_query % (tx_str)\n",
    "            result = self.run_query(query)\n",
    "            df = pd.json_normalize(result['data']['solana']['transfers'])\n",
    "            xfers.append(df)\n",
    "            print(datetime.now(), df.shape[0], \"transfers scraped in batch %d\" % i)\n",
    "\n",
    "        df_xfer = pd.concat(xfers, ignore_index=False)\n",
    "        df_xfer = df_xfer.rename(\n",
    "            columns={\n",
    "                \"block.timestamp.iso8601\": \"timestamp\", \n",
    "                \"instruction.action.name\": \"instructionAction\", \n",
    "                \"instruction.callPath\": \"instructionOrder\", \n",
    "                \"transaction.signer\": \"userAddress\", \n",
    "                \"transaction.signature\": \"txSignature\", \n",
    "                \"currency.symbol\": \"currencySymbol\", \n",
    "                \"currency.name\": \"currencyName\", \n",
    "                \"receiver.address\": \"receiverAddress\", \n",
    "                \"sender.address\": \"senderAddress\", \n",
    "                \"currency.decimals\": \"currencyDecimals\",\n",
    "                \"currency.address\": \"currencyAddress\", \n",
    "                \"sender.mintAccount\": \"senderTokenMint\"\n",
    "            }\n",
    "          )\n",
    "        \n",
    "        print(datetime.now(), df_xfer.shape[0], \"transfers retrieved\")\n",
    "\n",
    "        df_old = self.get_existing_df(fname)\n",
    "        df_final = df_old.append(df_xfer, ignore_index=True).sort_values(\"instructionOrder\")\n",
    "        \n",
    "        return df_final\n",
    "    \n",
    "\n",
    "    def parse_deposits(self):\n",
    "        instructionType = 'Deposit'\n",
    "        instructionAction = \"transfer\"\n",
    "        tx_merge_key = \"receiverAddress\"\n",
    "        meta_merge_key = \"vaultAuthority\"\n",
    "        out_file = self.deposit_fname\n",
    "        \n",
    "        self.parse_base(instructionType, instructionAction, tx_merge_key, meta_merge_key, out_file)\n",
    "        \n",
    "\n",
    "    def parse_withdrawal(self):\n",
    "        instructionType = 'Withdraw'\n",
    "        instructionAction = \"transfer\"\n",
    "        tx_merge_key = \"currencyAddress\"\n",
    "        meta_merge_key = \"shareTokenMint\"\n",
    "        out_file = self.withdraw_fname\n",
    "        \n",
    "        self.parse_base(instructionType, instructionAction, tx_merge_key, meta_merge_key, out_file)\n",
    "        \n",
    "        \n",
    "    def parse_deposit_cancel(self):\n",
    "        instructionType = 'CancelPendingDeposit'\n",
    "        instructionAction = \"transfer\"\n",
    "        tx_merge_key = \"senderAddress\"\n",
    "        meta_merge_key = \"vaultAuthority\"\n",
    "        out_file = self.withdraw_fname\n",
    "        \n",
    "        self.parse_base(instructionType, instructionAction, tx_merge_key, meta_merge_key, out_file)\n",
    "                \n",
    "        \n",
    "    def parse_withdrawal_cancel(self):\n",
    "        instructionType = 'CancelPendingWithdrawal'\n",
    "        instructionAction = \"mintTo\"\n",
    "        tx_merge_key = \"currencyAddress\"\n",
    "        meta_merge_key = \"shareTokenMint\"\n",
    "        out_file = self.withdraw_cxl_fname\n",
    "        \n",
    "        self.parse_base(instructionType, instructionAction, tx_merge_key, meta_merge_key, out_file)\n",
    "\n",
    "        \n",
    "    def parse_claim_withdrawal(self):\n",
    "        instructionType = 'ClaimPendingWithdrawal'\n",
    "        instructionAction = \"transfer\"\n",
    "        tx_merge_key = \"senderAddress\"\n",
    "        meta_merge_key = \"vaultAuthority\"\n",
    "        out_file = self.withdraw_claim_fname\n",
    "\n",
    "        self.parse_base(instructionType, instructionAction, tx_merge_key, meta_merge_key, out_file)\n",
    "\n",
    "        \n",
    "    def parse_base(self, instructionType, instructionAction, tx_merge_key, meta_merge_key, output_file):\n",
    "        \"\"\"\n",
    "        generalized method for parsing transfer data. \n",
    "        \n",
    "        1. Call get_batched_xfers()\n",
    "        2. for each unique txSignature, find the xfer matching to the last instance of the instructionAction\n",
    "        3. Join it to the friktion metadata based using tx_merge_key and meta_merge_key\n",
    "        4. Drop extraneous rows\n",
    "        5. Save the file to the output_file\n",
    "        \n",
    "        :instructionType: Type of instruction listed out in the instruction_match() method\n",
    "        :instructionAction: type of transfer we are matching towards\n",
    "        :tx_merge_key: what key in the xfer dataFrame do we want to merge on\n",
    "        :meta_merge_key: what key in the metadata dataFrame we want to merge on. \n",
    "        :output_file: as name suggests\n",
    "        \"\"\"\n",
    "        print(datetime.now(), \"Parsing transfers for instructionType: %s\" % instructionType)\n",
    "        df = self.get_batched_xfers(instructionType, output_file)\n",
    "        \n",
    "        # Get rid of confusing wSOL entries\n",
    "        df = df.query('currencyName != \"Wrapped SOL\"')\n",
    "\n",
    "        # The deposit is always the last mintTo instruction.\n",
    "        df = df.query('instructionAction==\"{}\"'.format(instructionAction)).groupby(\"txSignature\").last().reset_index()\n",
    "        \n",
    "        df = pd.merge(df, self.friktion_metadata, how='left',\n",
    "                      left_on=tx_merge_key, right_on=meta_merge_key, suffixes=('', '_drop'))\n",
    "        df.drop([col for col in df.columns if 'drop' in col], axis=1, inplace=True)\n",
    "        \n",
    "        df.drop_duplicates().to_csv(output_file, index=False)\n",
    "        print(datetime.now(), \"{} data size: {}\".format(instructionType, df.shape[0]))  \n",
    "        \n",
    "        \n",
    "    def parse_all(self):\n",
    "        self.get_ix_batch()\n",
    "#         self.parse_claim_withdrawal()\n",
    "#         self.parse_deposit_cancel()\n",
    "#         self.parse_withdrawal_cancel()\n",
    "        self.parse_deposits()\n",
    "        self.parse_withdrawal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a4d7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = \"2022-03-15T00:00:00Z\"\n",
    "date_end = \"2022-03-18T00:00:00Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85819620",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MyPortfolio(date_start, date_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1cf2981",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-15T00:00:00+00:00 2022-03-18T00:00:00+00:00\n",
      "2022-03-31 00:04:54.379555 retrieving instructions for 2022-03-15T00:00:00+00:00 to 2022-03-18T00:00:00+00:00\n",
      "2022-03-31 00:04:55.695965 963 instructions retrieved\n",
      "2022-03-31 00:04:55.702759 final instruction data size:  963\n",
      "2022-03-31 00:04:55.734187 wrote instruction data to csv...\n",
      "2022-03-31 00:04:55.734463 Parsing transfers for instructionType: Deposit\n",
      "2022-03-31 00:04:55.736571 6 signature batches required...\n",
      "2022-03-31 00:04:56.771643 298 transfers scraped in batch 0\n",
      "2022-03-31 00:04:57.809062 327 transfers scraped in batch 1\n",
      "2022-03-31 00:04:59.017150 343 transfers scraped in batch 2\n",
      "2022-03-31 00:05:00.263694 336 transfers scraped in batch 3\n",
      "2022-03-31 00:05:01.127824 282 transfers scraped in batch 4\n",
      "2022-03-31 00:05:01.898991 123 transfers scraped in batch 5\n",
      "2022-03-31 00:05:01.916065 1709 transfers retrieved\n",
      "2022-03-31 00:05:01.975704 Deposit data size: 417\n",
      "2022-03-31 00:05:01.976450 Parsing transfers for instructionType: Withdraw\n",
      "2022-03-31 00:05:01.979205 3 signature batches required...\n",
      "2022-03-31 00:05:03.035754 256 transfers scraped in batch 0\n",
      "2022-03-31 00:05:04.889431 340 transfers scraped in batch 1\n",
      "2022-03-31 00:05:05.664892 7 transfers scraped in batch 2\n",
      "2022-03-31 00:05:05.679707 603 transfers retrieved\n",
      "2022-03-31 00:05:05.699138 Withdraw data size: 91\n"
     ]
    }
   ],
   "source": [
    "x.parse_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db65bbb9",
   "metadata": {},
   "source": [
    "# Data Fidelity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1ece2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ix = pd.read_csv(\"friktion_ix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb5534f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix.loc[ix.instructionType==\"Withdraw\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfa9f86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deposit_ix = ix.loc[ix.instructionType==\"Withdraw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8077b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = set(deposit_ix.txSignature.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2789567c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deposits = pd.read_csv(\"friktion_withdraw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70b9ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = set(deposits.txSignature.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a4bd411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95250423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ba31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "247c5f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txSignature</th>\n",
       "      <th>amount</th>\n",
       "      <th>instructionAction</th>\n",
       "      <th>instruction.action.type</th>\n",
       "      <th>instructionOrder</th>\n",
       "      <th>userAddress</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>currencyName</th>\n",
       "      <th>currencyAddress</th>\n",
       "      <th>currencySymbol</th>\n",
       "      <th>currencyDecimals</th>\n",
       "      <th>senderAddress</th>\n",
       "      <th>senderTokenMint</th>\n",
       "      <th>receiverAddress</th>\n",
       "      <th>receiver.mintAccount</th>\n",
       "      <th>globalId</th>\n",
       "      <th>vaultAuthority</th>\n",
       "      <th>shareTokenMint</th>\n",
       "      <th>depositTokenSymbol</th>\n",
       "      <th>depositTokenCoingeckoId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [txSignature, amount, instructionAction, instruction.action.type, instructionOrder, userAddress, timestamp, currencyName, currencyAddress, currencySymbol, currencyDecimals, senderAddress, senderTokenMint, receiverAddress, receiver.mintAccount, globalId, vaultAuthority, shareTokenMint, depositTokenSymbol, depositTokenCoingeckoId]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deposits.loc[deposits.txSignature==\"23NwhjEVdLf5hW86LW9ph3Xu7mGmdmQkdmjzgM1rppxuFxqtb3NpNz9DoDuYN4CKGHzCEEjwkj4PQKf2s6pJ2g41\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5faf549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23NwhjEVdLf5hW86LW9ph3Xu7mGmdmQkdmjzgM1rppxuFxqtb3NpNz9DoDuYN4CKGHzCEEjwkj4PQKf2s6pJ2g41',\n",
       " '2APcgdqnRARfU1TU6zUkfmKEK5v3uRe8sgFAbMwezjwnu662A4enqL8QAZGnKBxnWgaCUwakFVgoYopEPkVLwfg1',\n",
       " '2GgDRPNGRiHTEgEvd5hFbCBZQzQsV9udFh2pdgoPg8tCHZLCzTvaU1pDWL6y8HjMKvspNkqvUD2dvn23CgS47xwC',\n",
       " '2SK1W44ATB1831jieFZqaZJBQqvZgujAJmxFX1KkhN7DQQXUT84JV7ncNb7NyNxrxF46f4BsEeEoqnWCy8nSKwKM',\n",
       " '2fckWYe7tiUrw2cpds8sBQmTkaozApt89ycfUc5bLNjKX3RUVgh8p1ttXKXF5P5Eco1Gt7hKXJgMjt9WmcxVqjMt',\n",
       " '2mYj6MJtP5eEcMZDncsLss8PqrMgDc9oU61sbvEKg6UZPcYXFkH2TxY81mWEXY2UJYxUg4TcxpaTMcfomMMkUiSz',\n",
       " '2pMReXtrtXFUYuTdKEwAhop1bTawsMRr7rrcWtKEnRpxQviigiRAcCiZgQP2yz7bZPPyJsYf78RbjE1ZoM6pMttX',\n",
       " '2vxKfR38RpYyVN7HWXD5tpwwkXbDSSeSX1oqSgDQxqgP3X1nWcyLubjVXYUuffHVnteA1wNWdPEqfSwAoHtgL1pS',\n",
       " '2zdgybj6xuScpMNM7SmoeHg5wuyiRgkcvN2AtmcWFyE8RX5zsAnzodxvDLQbWdgHzZqj8AATbXkgSBV5vxnQUscH',\n",
       " '367NobXHJM4geu8ZMFqQMcUv5F4fGuEhj8sfxYHjP5o5VSXxb35gYjZZ8pFgxPQNbeyvcrBB7Ste1sbGSJTKT1kV',\n",
       " '3TTFDkYKARyfns2uSK2svMVXvPD5uQJZrXyRuFfEfrDjGA8h9DiyBLbdTaUugaT8DHufpiaYEe8HENDyY6xhha39',\n",
       " '3VLBbGiEuhsDBb3o64dEmdefTPVqk6SR7HtKPUzRUxUeE79mT7ACyriqBNfqquMwP4EFskoEhpFy2HrKEy9PCYTh',\n",
       " '3akH6ssqRXVCYJkAv3jTkdYi4Z6Xt7PSBSc8EZiAtXipc5G9HzxmDcFxH1YV2s9yFLhGUY9tjBNF2ewNhAzAK5rb',\n",
       " '3dBtR3wSiM5aNKujwcYzREKs2ewiyGZqZYpX7RQgQcPJqqZuCVnnhhGPA9wyGBqc6m4fX9ho5aXduqyTe7ux99Wj',\n",
       " '3jDVWtmxTQ7k7eBmWwS2Ueo6axuE2iYA2EBmNfbXcEY9yZdgCdhySoGxVWGszp3X9Sy9vxVgMgZLC6SS9xz53UFf',\n",
       " '3mttCggy5bMqoFW8Px3G35yBjztS2Eqe7L7Tg9BVUQBNTCxafWMHsDsUc1JmE49Acv4mAjPHFPV78Bb6qt7xFZ7H',\n",
       " '3nrnq7SPciwFE4BJz7SZQ9G33RvvLytNegt2kyZDNYpfzWpuTvrgNDJZuSNqegVRySMyYfuN3gXEx98FhHqH298d',\n",
       " '3sSBhknnoBn1vaAKhPu1uqc54quS3TgVD21TMVBuCzSKZvJh3r3VTSBhxymAh6HofQyuY99PHMJ5z9gooXddzZ7B',\n",
       " '3t8XR1LoUXkzhA1pDfhAYe1A7hohjfEZTeyesGtscG6UG5rwq7PJCghPoK4DSRjYfkeZpPQSPedwtAXFDMKn8Pk5',\n",
       " '3yDJbevziavxX2cihemDJbCZmRsxX4xv5bMdwFRkcUui1VndDvY7b4xPrxMHqsisEtmb7pNPgcJE1Znkf77TSYgF',\n",
       " '45WecEQYuCCKGdb5B4CRkQfbfaSuUiM5fbdNMNfMbCC1uLhWMQ8wKY4P8KgsmpR6NkpvFy1Yq7591B7GnJsR6BBG',\n",
       " '46f78N6A1jDqSYtRh3vEzS5sCSR81BJJVqiCi6F9eodPUnZhsBo8Ds1SPRCQHiWxFaTs9PpjxF5T2xJreWEqV42i',\n",
       " '47gzi42kqoWXN9y9P795cbENCqZNVgu2U76WUzC6RLkSW49Qw725PPUh9Dm8B7yaHe1esFYDRCWd5yRh95AvxMfF',\n",
       " '49wvLQKd7hTMBc45jLwskREH8miDgA3vXBE4Jrn4pyXTsY686UZmLRbZbcg8yV4dBbm7GVRoXLpKDgqKseNjpA7A',\n",
       " '4E2KrnYHuZeKE2eXeT3EQhmWEAgbXz5XrDreqVoPRzbJgEZC93PdBTyuUHB6wnojk4QpqhrLerMSpzPDp1nkbayH',\n",
       " '4F8VtwpLjYjDn1WAjFNUDPQcGHu8sVt3Wg6YC1WnNabxrSsRfaxSj9Er3Zq8BzcXe684jwRzc9ExkjAtyEP9zUpr',\n",
       " '4FqEuXjHzUxmDk7XyktFLgF12VPdztenNuuEXZtyyNt9G5bTpjVVoFJkyMFEfsPckCM8hGRvC6wnADqZQiEprx94',\n",
       " '4Kxs2DNBrFYtbL7L3vm9eGutWC9jNk8EUif4ZuaQu3YksHU6phfvgyCxVTCvjaQsPzUbdHsRzFcXbNmLfZaJvy6A',\n",
       " '4RoGZeDNQDDCprQwAL5jbZgwUjv9DrSUN2Cngjgoa4KFaRgmQ6PMS5truVYAuTuFWDU8p6uRiihLkffVrXWBM4y9',\n",
       " '4pd8k91SMvbasWu1oR7VrmHVhaNFciWeGmjvBUR3vGTRL3yZduLSfiZHfU7u5K3y6eAMivaEBspJQJYVtZ1h4GVU',\n",
       " '4rYwucFgumXDfCHsGTb2QTmQnsaGDdpQ9RLGppbnJvHfjQGw84bASxvDH3PmhNEjkbUUzBjRGn8tEVbY1mqwiW1f',\n",
       " '4vKZi43toXc9bUHBLJUkSANByHyZoh9T2D6iEnskFeYF2g8UrsoU9343hUdYTKyRN8Ygn75468pYTUx5cgvxidHe',\n",
       " '4vfG6TwrDUmDpFnc7e3z9bHphHzkYDYHFJHZWHhA9fPwMVQN39qQ8M7wZAWQV6X5D98heiseCUHUkG1KbzCyWAaT',\n",
       " '4xdHBt7E8DcB6B5UAMkyiE1782o32ehGTVe4Fy3DCouKweUSCekZ2vaDFemJMbtWC9ziwnkp4ESMfangg7dHnbfR',\n",
       " '56spLJXFt2voLhL7Mc8djfFtVJ6ZRvrXE8n25fVYQpBFKRLQtPVACdtDMVPm6Zg9Z55DYtgi3XnxLz43Emor6GuA',\n",
       " '5LQUiWVQQMBYmkPccnPsrx4AJ5Xiqf9FBA523tzxVxRvCnAA1uTSzq2VFGzPjh21mCeKYAps2f2biAsa3wTCbezc',\n",
       " '5PYuWZ68n69MywJZTmvwwTDVMNiz6zQ6WfLzH3xY5R85nj9x6KTnwysA6hJY3TDrju67sCmgqXXcJ4vhS1HMGk9P',\n",
       " '5SY9WadqeJy4tpLHyoGBSVHLKbhYxvUUwKHg2rVcCFf6u5t2hMjeMZhoiFFYDMNNUXDWKeC6i8i64ag6LJ74MHE7',\n",
       " '5bSUaRA1AMBTpFfufLBbbK6n6xQVerxTdeTjiJna8JiRfEkYgw9H8VyGYiW2mtBgbXWDncmRmcLfxSJNesbtqYpM',\n",
       " '5dG1dbajBVsC3NxEyQbaEQvF3N6TfYpX92Ve7mBy35HYTWFfABhgQNXRjeufXp5EyYJN1mWiAa8Xsn7u3g8V6f5R',\n",
       " '5eevi7xtBc9LEkYvy1fdHnoJVw545vtpQ4ku4wNGQgMqdM6FvR3K1U6Zbzpc9y69gYt4tqJ9i2VZmZ2VgKHiozAw',\n",
       " '5ftVX7gb1dYh2qXhb3gch16SVSv3dDDv2VnqQiK7F5XczdG7ezaPt6ArP7mJqXbDSADdWcjKKQXSyv4jUYFMm3an',\n",
       " '5ivS92zfMvgFbWRe5BMnpad7NVWjoMCgtVUeLohYv5cxJX3gjfF9kULjaFscdyxZbjgEWzzWLcQXmRZoSnmCoHfF',\n",
       " '5wEkAPE7yptHsgQQxH4xyiZRizoPnfmqpMQ269JCr3YLWp1fcb7jn4etvVpdWqhQfkaRsxmizb2xcY9WC2wiufVb',\n",
       " '5z3RbqVjfHzgVf492Rxk4yfsnkwxwUbGua5zCfF3Cfx5TpTcYbnbo1g5iZ4ofgDZXHVwe6619zHrzqoaAWaqXbdA',\n",
       " '5zdNNAsnvDVyoznDGUuV1NoQZ9UmhJn79dKrUrEMZTS4pB5kuR9fAYr6EcMfe3eBAUew2Nr7FRfkQEiizoUAwM6r',\n",
       " '62QVQinGLQLuGiwG19Se19nRgCnvkbcWqXK52mcUeMX6fCYRs6aGMjg9CRc9DMBUo9VUxcjnNuyRYPDrbeo1BMjX',\n",
       " '9b6azRy6nXbe6Meuq7KTVruownfEjWsp8APsucdgrv7Gr39LzeuorqzeNopWRzcHs6NWFy89YnGGHDVrKYhtHuf',\n",
       " 'B8Dmg8MULgbdAnsFT95bqLjgVgfceaXzAB31sRNBazzDeC5m34Wspp3HvxV8BX8LKpiaxYthqwx8d2me7GVBxxm',\n",
       " 'GhEViEDxNTvuSHJnEMKkgn897D818vHPPzBDZdzyPtDiAcHmpeZtkDvqdG2ZhL2RAbQngBGp7vqpNg64zKWjTEN',\n",
       " 'Gr5SAam6DFZZDdT8xVYsQeKPYcKjMWHMpJWoqLBVV2qiDjR6iZBP2XeFAVbYUeuLzSveeZ25yuLpMrviWEaVRs5',\n",
       " 'SNKQvzHR6cKgMkLGf4NYP3ypky1vkhUZBSFLomw2kFTDXPb3apm35xqhZgRx1GgZ3oxmHyquRsWprnjuutLqwbe',\n",
       " 'Sdthc7VVqH7uSPFg94LiHW1CMzyVVjoYLXYRW6MwW7b2me6h4ogB8dENHw2oZFYXwXtVuemA7oWS4CHL7ek6Hvs',\n",
       " 'SqN2Q8aM1suqdEiriEJMSJnwdYWcNE73t4tF94SzeTYiHp7XnRvVvQue1qrpEy6hno7aEFAW5Bsi6R7uYbhbFFQ',\n",
       " 'UNyr2X8WuBF3sjnsRQjXrjaidZnVefbnvCbeVPMcN51Mbn1sAjo8Z5XLnNE5AVZKVSuS1zdq8GssHbw4myUTpvb',\n",
       " 'cXDUEuYCBr7RZQi2eB85vRe93RmfvUH1hYafcJmZ6CZgPfVLZq8QnBb3M3ADErEkXYCP84H37s6dfJp5FQNvdC1',\n",
       " 'dArsvYqpFZNTNgdsjZQj3V3pQ1oUmaRKUHwZnQYDHJPUBCKZrEForGXFdn69kgTp3WPBZCzhR8xCGyynEPNJd3J',\n",
       " 'iKCAfPxabyuaSwZjdPtshb4yX3XRSf9CxECjDiF82Sn1JQrggwGs3TJzcZv92WYw4JBRFHATVxTN8dBz62dFjwP',\n",
       " 'iiYNL7nv7w5RWYiKcGsvTxF5mqoUTk4Lc3Cs1KcQarphxmaKQmmXaHwRSmZdocGiiHRHzTEPzQXiF35zyCWQh3d',\n",
       " 'tUHqiJzXmVwfS8WfcKVDiZwC2j5j5vq1K5Vsy49ie7CGq7j1QYbcj1sg1nNc1UHJCBShdUN6gQPpsarTggmkA1j',\n",
       " 'xNfey1iWTa2XRnkBPavaXsUKNFvv7y9MCZgf6vZBk9QsLE8JZ9WS52kF4pMBWLVQ5WbzuQ9wSds3v2pnwzn8bfR',\n",
       " 'yLykTWbxYggJYhbjYEbEmmFBkihoUNojSnRiBNcEJHA4miUJT3euwDWQ3B2DcGfyFLrYCf9LRTguNtga798mqky'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg.difference(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7b40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
